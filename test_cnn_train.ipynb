{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from record_utils import RecordManager\n",
    "\n",
    "\n",
    "LOAD_OLD_MODEL = False \n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "TEST_BATCH_SIZE = 64\n",
    "VIZ_BATCH_SIZE = 5\n",
    "\n",
    "CHECKPOINT_PATH = \"./checkpoints/cifar/checkpoint_1.0pth\"\n",
    "CHECKPOINT_FOLDER_PATH = \"./models/cifar10\"\n",
    "\n",
    "CIFAR10_CLASSES = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize to mean=0.5, std=0.5 for each channel\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "viz_loader = torch.utils.data.DataLoader(test_dataset, batch_size=VIZ_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train size:\",len(train_loader.dataset))\n",
    "print(\"Test size:\",len(test_loader.dataset))\n",
    "\n",
    "from collections import defaultdict \n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Iterate through the test_loader\n",
    "for _, labels in test_loader:\n",
    "    for label in labels:\n",
    "        class_counts[label.item()] += 1\n",
    "\n",
    "# Print counts per class\n",
    "for class_idx, count in class_counts.items():\n",
    "    print(f\"Class {class_idx}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(viz_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "\n",
    "# Show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % train_dataset.classes[labels[j]] for j in range(VIZ_BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract a subset of images from two classes (e.g., cats and dogs)\n",
    "#class_indices = [train_dataset.class_to_idx['cat'], train_dataset.class_to_idx['dog']]\n",
    "#subset_indices = [i for i, label in enumerate(train_dataset.targets) if label in class_indices]\n",
    "#subset_images = [train_dataset[i][0].numpy().flatten() for i in subset_indices]\n",
    "#subset_labels = [train_dataset[i][1] for i in subset_indices]\n",
    "#\n",
    "## Convert the list of images to a NumPy array\n",
    "#subset_images = np.array(subset_images)\n",
    "#\n",
    "## Perform t-SNE\n",
    "#tsne = TSNE(n_components=2, random_state=42)\n",
    "#tsne_result = tsne.fit_transform(subset_images)\n",
    "#\n",
    "## Create a scatter plot\n",
    "#plt.figure(figsize=(8, 6))\n",
    "#colors = ['red' if label == class_indices[0] else 'blue' for label in subset_labels]\n",
    "#plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=colors, alpha=0.5)\n",
    "#plt.title('t-SNE Visualization of Two Classes (Cats and Dogs) in CIFAR-10')\n",
    "#plt.xlabel('t-SNE Component 1')\n",
    "#plt.ylabel('t-SNE Component 2')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(512)\n",
    "        #self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32768, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(self.relu(self.conv1(x)))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.batchnorm2(self.relu(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.batchnorm3(self.relu(self.conv5(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(self.relu(self.fc2(self.relu(self.fc1(self.flatten(x))))))\n",
    "        return x\n",
    "\n",
    "model = DeepCNN().to(device)\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNNResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DeepCNNResNet, self).__init__()\n",
    "        # Load a pre-trained ResNet18 model\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify the final fully connected layer to match the number of classes\n",
    "        in_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "        # Add dropout for regularization (optional)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.base_model(x))\n",
    "        return x\n",
    "    \n",
    "#model = DeepCNNResNet().to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "record_manager = RecordManager(CHECKPOINT_FOLDER_PATH)\n",
    "\n",
    "#Load state dict\n",
    "if LOAD_OLD_MODEL:\n",
    "    checkpoint = torch.load('./checkpoints/cifar/checkpoint_4.1.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n",
    "\n",
    "best_test_accuracy = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader)}, Accuracy: {accuracy}\")\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    test_accuracy = total_correct / total_samples\n",
    "    if test_accuracy > 0.8 and test_accuracy > best_test_accuracy: \n",
    "        record_manager.save_checkpoint(model, optimizer,running_loss, epoch, test_accuracy=test_accuracy,train_accuracy=accuracy)\n",
    "        best_test_accuracy = test_accuracy\n",
    "    else:\n",
    "        record_manager.save_metrics(running_loss, epoch, train_accuracy=accuracy, test_accuracy=test_accuracy)            \n",
    "    print(f\"    Test Accuracy: {test_accuracy:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def get_latent_features(model, data_loader, layer_name):\n",
    "    model.eval()\n",
    "    intermediate_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Register a forward hook to capture the intermediate layer's output\n",
    "    def hook(module, input, output):\n",
    "        intermediate_outputs.append(output.cpu().numpy())\n",
    "\n",
    "    hook_handler = model._modules[layer_name].register_forward_hook(hook)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            _ = model(inputs)  # Trigger the forward pass to collect the intermediate features\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    hook_handler.remove()  # Remove the hook to avoid affecting subsequent forward passes\n",
    "\n",
    "    return np.concatenate(intermediate_outputs), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "# Choose an intermediate layer for t-SNE visualization\n",
    "intermediate_layer_name = 'fc3'  # You can change this to the desired layer\n",
    "\n",
    "# Get latent features and labels from the specified intermediate layer\n",
    "features, labels = get_latent_features(model, test_loader, intermediate_layer_name)\n",
    "\n",
    "# Reshape the features if needed (e.g., flatten for fully connected layers)\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Use t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "latent_tsne = tsne.fit_transform(features)\n",
    "\n",
    "# Plot t-SNE visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = sns.scatterplot(x=latent_tsne[:, 0], y=latent_tsne[:, 1], hue=labels, palette=\"tab10\", legend=\"full\")\n",
    "scatter.set_title(f\"t-SNE Visualization of Latent Features from {intermediate_layer_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCNNMinReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepCNNMinReg, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(256, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(1024)\n",
    "        #self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(65536, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(self.relu(self.conv1(x)))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.batchnorm2(self.relu(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.batchnorm3(self.relu(self.conv6(x)))\n",
    "        x = self.fc3(self.relu(self.fc2(self.relu(self.fc1(self.flatten(x))))))\n",
    "        return x\n",
    "\n",
    "noreg_model = DeepCNNMinReg().to(device)\n",
    "summary(noreg_model, (3, 32, 32))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 16, 16]          12,288\n",
      "       BatchNorm2d-2          [-1, 256, 16, 16]             512\n",
      "              ReLU-3          [-1, 256, 16, 16]               0\n",
      "            Conv2d-4            [-1, 256, 8, 8]       1,048,576\n",
      "       BatchNorm2d-5            [-1, 256, 8, 8]             512\n",
      "              ReLU-6            [-1, 256, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 4, 4]       1,048,576\n",
      "       BatchNorm2d-8            [-1, 256, 4, 4]             512\n",
      "              ReLU-9            [-1, 256, 4, 4]               0\n",
      "           Conv2d-10            [-1, 128, 2, 2]         524,288\n",
      "      BatchNorm2d-11            [-1, 128, 2, 2]             256\n",
      "             ReLU-12            [-1, 128, 2, 2]               0\n",
      "           Conv2d-13            [-1, 128, 1, 1]          65,664\n",
      "================================================================\n",
      "Total params: 2,701,184\n",
      "Trainable params: 2,701,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.98\n",
      "Params size (MB): 10.30\n",
      "Estimated Total Size (MB): 12.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models import CNN\n",
    "from tqdm import tqdm\n",
    "model = CNN([256,256,256,128,128]).to(\"cuda\")\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.6707916875629474, Accuracy: 0.35782\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 1.9226759080691715, Accuracy: 0.43722\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:16<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.6397298870184231, Accuracy: 0.48246\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 1.4824046427026734, Accuracy: 0.51676\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 1.37549695029588, Accuracy: 0.54462\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:13<00:00, 28.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 1.2903986538157743, Accuracy: 0.56868\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:15<00:00, 25.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 1.2189611027307827, Accuracy: 0.59242\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 1.155759786553395, Accuracy: 0.61134\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 1.1002621210139731, Accuracy: 0.63074\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:13<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 1.050122105404544, Accuracy: 0.64788\n",
      "Metrics updated in: ./models/cifar10\\run10\\accuracies\\all_accuracies.json\n",
      "    Test Accuracy: 0.6293\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.001)\n",
    "record_manager = RecordManager(CHECKPOINT_FOLDER_PATH)\n",
    "\n",
    "#Load state dict\n",
    "SAVE_METRICS = True\n",
    "SAVE_MODEL = True\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader)}, Accuracy: {accuracy}\")\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    test_accuracy = total_correct / total_samples\n",
    "\n",
    "\n",
    "\n",
    "    if test_accuracy > 0.8 and test_accuracy > best_test_accuracy: \n",
    "        if SAVE_MODEL:\n",
    "            record_manager.save_checkpoint(model, optimizer,running_loss/len(train_loader), epoch, test_accuracy=test_accuracy, train_accuracy=accuracy)\n",
    "        best_test_accuracy = test_accuracy\n",
    "    else:\n",
    "        if SAVE_METRICS:\n",
    "            record_manager.save_metrics(running_loss/len(train_loader), epoch, train_accuracy=accuracy, test_accuracy=test_accuracy)       \n",
    "    print(f\"    Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        #self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        #self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(8192, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm1(self.relu(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.fc3(self.relu(self.fc2(self.relu(self.fc1(self.flatten(x))))))\n",
    "        return x\n",
    "    \n",
    "\n",
    "simple_model = SimpleCNN().to(device)\n",
    "summary(simple_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=0.0001, weight_decay=0.001)\n",
    "record_manager = RecordManager(CHECKPOINT_FOLDER_PATH)\n",
    "from models import TriggerSensitiveCNN\n",
    "\n",
    "#Load state dict\n",
    "SAVE_METRICS = True\n",
    "SAVE_MODEL = True\n",
    "\n",
    "best_test_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    simple_model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = simple_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader)}, Accuracy: {accuracy}\")\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    simple_model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = simple_model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_correct += predicted.eq(labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    test_accuracy = total_correct / total_samples\n",
    "\n",
    "\n",
    "\n",
    "    if test_accuracy > 0.8 and test_accuracy > best_test_accuracy: \n",
    "        if SAVE_MODEL:\n",
    "            record_manager.save_checkpoint(simple_model, optimizer,running_loss/len(train_loader), epoch, test_accuracy=test_accuracy, train_accuracy=accuracy)\n",
    "        best_test_accuracy = test_accuracy\n",
    "    else:\n",
    "        if SAVE_METRICS:\n",
    "            record_manager.save_metrics(running_loss/len(train_loader), epoch, train_accuracy=accuracy, test_accuracy=test_accuracy)       \n",
    "    print(f\"    Test Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
